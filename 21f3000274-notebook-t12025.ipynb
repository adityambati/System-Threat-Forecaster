{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90791,"databundleVersionId":10592855,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:46.548226Z","iopub.execute_input":"2025-03-21T02:50:46.548529Z","iopub.status.idle":"2025-03-21T02:50:46.922461Z","shell.execute_reply.started":"2025-03-21T02:50:46.548505Z","shell.execute_reply":"2025-03-21T02:50:46.921555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def submit_for_score(model):\n    test_df = pd.read_csv(\"/kaggle/input/System-Threat-Forecaster/test.csv\")\n\n    # Applying Date Transformer before preprocessing\n    #date_cols = ['DateAS', 'DateOS']\n    #date_transformer = DateTransformer(date_columns=date_cols)\n    #test_df = date_transformer.transform(test_df)\n\n    X_test = test_df.drop(columns=['target'], errors='ignore')\n    X_test_processed = preprocessor.transform(X_test)\n\n    # predictions\n    pred = model.predict(X_test_processed)\n\n    # submission file\n    submission = pd.DataFrame({\"id\": range(0, X_test.shape[0]), \"target\": pred})\n    submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:46.923673Z","iopub.execute_input":"2025-03-21T02:50:46.924253Z","iopub.status.idle":"2025-03-21T02:50:46.929179Z","shell.execute_reply.started":"2025-03-21T02:50:46.924216Z","shell.execute_reply":"2025-03-21T02:50:46.928264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:46.930825Z","iopub.execute_input":"2025-03-21T02:50:46.931088Z","iopub.status.idle":"2025-03-21T02:50:47.924822Z","shell.execute_reply.started":"2025-03-21T02:50:46.931064Z","shell.execute_reply":"2025-03-21T02:50:47.923749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **1. Data Loading**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/System-Threat-Forecaster/train.csv')\ntest_df = pd.read_csv('/kaggle/input/System-Threat-Forecaster/test.csv')\n\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:47.926403Z","iopub.execute_input":"2025-03-21T02:50:47.926839Z","iopub.status.idle":"2025-03-21T02:50:49.794636Z","shell.execute_reply.started":"2025-03-21T02:50:47.926813Z","shell.execute_reply":"2025-03-21T02:50:49.793621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **2. Exploratory Data Analysis**","metadata":{}},{"cell_type":"markdown","source":"**Data Types and missing values of columns**","metadata":{}},{"cell_type":"code","source":"print(\"Train dataset shape:\", train_df.shape)\nprint(\"Test dataset shape:\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:49.795583Z","iopub.execute_input":"2025-03-21T02:50:49.795892Z","iopub.status.idle":"2025-03-21T02:50:49.801732Z","shell.execute_reply.started":"2025-03-21T02:50:49.795857Z","shell.execute_reply":"2025-03-21T02:50:49.800777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Displaying column data types and missing values\nprint(\"\\nColumn Data Types:\")\nprint(train_df.dtypes)\n\nprint(\"\\nMissing Values in Train Dataset:\")\nnull_summary1 = train_df.isnull().sum()[train_df.isnull().sum() > 0].to_frame(name='Null Count')\nnull_summary1['Null Percentage (%)'] = (train_df.isna().sum() / len(train_df)) * 100\nprint(null_summary1)\n\nprint(\"\\nMissing Values in Test Dataset:\")\nnull_summary2 = test_df.isnull().sum()[test_df.isnull().sum() > 0].to_frame(name='Null Count')\nnull_summary2['Null Percentage (%)'] = (test_df.isna().sum() / len(test_df)) * 100\nprint(null_summary2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:49.802782Z","iopub.execute_input":"2025-03-21T02:50:49.803102Z","iopub.status.idle":"2025-03-21T02:50:50.298962Z","shell.execute_reply.started":"2025-03-21T02:50:49.803067Z","shell.execute_reply":"2025-03-21T02:50:50.297883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***Insights from data***\n* Column 'SMode' has the highest Null Count Percentage (most number of missing values)\n* Column 'ChassisType' has the least Null Count Percentage ( apart from columns having no missing values)","metadata":{}},{"cell_type":"markdown","source":"**Checking unique values in categorical columns**","metadata":{}},{"cell_type":"code","source":"cat_cols = train_df.select_dtypes(include=['object']).columns\ntrain_df[cat_cols].nunique().sort_values(ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:50.300035Z","iopub.execute_input":"2025-03-21T02:50:50.300395Z","iopub.status.idle":"2025-03-21T02:50:50.527565Z","shell.execute_reply.started":"2025-03-21T02:50:50.300358Z","shell.execute_reply":"2025-03-21T02:50:50.526568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n***Insights from data***\n* Column 'MachineID' has the highest number of Unique values (99835)\n* Column 'DateAS' has too many values and hence we can build a date transformer under feature engineering.\n* Column 'ProductName' and 'DeviceFamily' has the least number of Unique values (2)","metadata":{}},{"cell_type":"markdown","source":"**Numerical columns and their statistics**","metadata":{}},{"cell_type":"code","source":"train_df.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:50.528603Z","iopub.execute_input":"2025-03-21T02:50:50.528953Z","iopub.status.idle":"2025-03-21T02:50:50.792631Z","shell.execute_reply.started":"2025-03-21T02:50:50.528923Z","shell.execute_reply":"2025-03-21T02:50:50.791552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Feature distribution of Categorical Columns**","metadata":{}},{"cell_type":"code","source":"cat_cols = train_df.select_dtypes(include=['object']).columns\n\n# Value Counts (Excluding High-Cardinality Features)\nsummary_data = []\n\nfor col in cat_cols:\n    unique_count = train_df[col].nunique()\n    if unique_count > 50:  \n        continue\n\n    top_value = train_df[col].value_counts(normalize=True).values[0] * 100\n\n    summary_data.append([col, unique_count, round(top_value, 2)])\n\nsummary_df = pd.DataFrame(summary_data, columns=[\"Feature\", \"Unique Categories\", \"Top Value %\"])\n\n\nsummary_df = summary_df.sort_values(by=\"Top Value %\", ascending=False)\n\nprint(\"Categorical Feature Summary (Top 10 Shown)\")\nprint(summary_df.head(10))\n\n# High Cardinality Detection\nhigh_cardinality_cols = summary_df[summary_df[\"Unique Categories\"] > 10][\"Feature\"].tolist()\nprint(f\"\\n High Cardinality Columns (>10 categories): {high_cardinality_cols}\")\n\n# smaller visualizations (Top 5 values for low-cardinality columns)\nlow_cardinality_cols = summary_df[summary_df[\"Unique Categories\"] <= 10][\"Feature\"].tolist()\n\nnum_plots = min(len(low_cardinality_cols), 15)\nfig, axes = plt.subplots(nrows=(num_plots // 3) + 1, ncols=3, figsize=(15, num_plots * 1.5))\n\nfor i, col in enumerate(low_cardinality_cols[:num_plots]):\n    ax = axes[i // 3, i % 3]\n    sns.countplot(data=train_df, x=col, order=train_df[col].value_counts().index[:5], palette='Set2', ax=ax)\n    ax.set_title(f\"{col} Distribution\")\n    ax.tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:50.795715Z","iopub.execute_input":"2025-03-21T02:50:50.795982Z","iopub.status.idle":"2025-03-21T02:50:54.675264Z","shell.execute_reply.started":"2025-03-21T02:50:50.795958Z","shell.execute_reply":"2025-03-21T02:50:54.674272Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Target Variable Analysis**","metadata":{}},{"cell_type":"code","source":"print(\"Target Variable Distribution\")\nprint(train_df['target'].value_counts())\nprint(\"\\n Target Variable Distribution (Percentage)\")\nprint(train_df['target'].value_counts(normalize=True) * 100)\n\nplt.figure(figsize=(6, 6))\ntrain_df['target'].value_counts().plot.pie(\n    autopct=\"%1.1f%%\", \n    colors=[\"blue\", \"red\"], \n    startangle=90, \n    wedgeprops={\"edgecolor\": \"black\"}\n)\n\nplt.title(\"Target Variable Distribution\", fontsize=14)\nplt.ylabel(\"\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:54.677141Z","iopub.execute_input":"2025-03-21T02:50:54.677458Z","iopub.status.idle":"2025-03-21T02:50:54.841908Z","shell.execute_reply.started":"2025-03-21T02:50:54.677430Z","shell.execute_reply":"2025-03-21T02:50:54.841045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* ***The dataset seems very balanced, with 50.5% of the target variable being '1' and only 49.5% being '0'***","metadata":{}},{"cell_type":"markdown","source":"**Distribution of Numeric Categories**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnum_columns = train_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n\n# grid layout\nn_cols = 3  \nn_rows = (len(num_columns) + n_cols - 1) // n_cols\n\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(14, n_rows * 3))\naxes = axes.flatten()\n\nfor i, col in enumerate(num_columns):\n    axes[i].hist(train_df[col].dropna(), bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.7)\n    axes[i].set_title(f\"{col} Distribution\", fontsize=11, pad=5)\n    axes[i].set_xlabel(col)\n    axes[i].set_ylabel(\"Frequency\")\n\nfor j in range(i + 1, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:50:54.842836Z","iopub.execute_input":"2025-03-21T02:50:54.843211Z","iopub.status.idle":"2025-03-21T02:51:05.208851Z","shell.execute_reply.started":"2025-03-21T02:50:54.843157Z","shell.execute_reply":"2025-03-21T02:51:05.207617Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Pie Chart for Distribution of Categorical Features**","metadata":{}},{"cell_type":"code","source":"# Detecting categorical columns with low cardinality\ncat_columns = train_df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\nlow_cardinality_cols = [col for col in cat_columns if train_df[col].nunique() <= 50]\n\n# grid layout\nn_cols = 3  \nn_rows = (len(low_cardinality_cols) + n_cols - 1) // n_cols\n\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(14, n_rows * 3))\naxes = axes.flatten()\n\nfor i, col in enumerate(low_cardinality_cols):\n    counts = train_df[col].value_counts(normalize=True)\n    \n    # Merging small categories (<5%) into \"Others\"\n    small_threshold = 0.05\n    large_categories = counts[counts >= small_threshold]\n    small_categories_sum = counts[counts < small_threshold].sum()\n    \n    if small_categories_sum > 0:\n        large_categories[\"Others\"] = small_categories_sum\n    \n    # pie chart\n    wedges, texts, autotexts = axes[i].pie(\n        large_categories, labels=None, autopct=lambda p: f'{p:.1f}%' if p > 5 else '',\n        startangle=90, colors=plt.cm.Paired.colors, wedgeprops={\"edgecolor\": \"black\", \"linewidth\": 1}\n    )\n    \n    axes[i].set_title(f\"{col} Distribution\", fontsize=11, pad=5)\n    axes[i].legend(large_categories.index, loc=\"best\", fontsize=8)\n\n\nfor j in range(i + 1, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:05.210184Z","iopub.execute_input":"2025-03-21T02:51:05.210578Z","iopub.status.idle":"2025-03-21T02:51:08.341575Z","shell.execute_reply.started":"2025-03-21T02:51:05.210538Z","shell.execute_reply":"2025-03-21T02:51:08.340501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **3.Feature Engineering / Data Pre-Processing**","metadata":{}},{"cell_type":"code","source":"#from sklearn.base import BaseEstimator, TransformerMixin\n\n#class DateTransformer(BaseEstimator, TransformerMixin):\n#    def __init__(self, date_columns=None):\n#        self.date_columns = date_columns if date_columns else []\n    \n#    def fit(self, X, y=None):\n#        return self\n\n#    def transform(self, X):\n#        X = X.copy()\n        \n#        for col in self.date_columns:\n#            if col == 'DateAS':\n                # Converting 'DateAS' format: 'YYYY-MM-DD HH:MM:SS' (Datetime with Time)\n#                X[col] = pd.to_datetime(X[col], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n#            elif col == 'DateOS':\n                # Converting 'DateOS' format: 'YYYY-MM-DD' (Date Only)\n#                X[col] = pd.to_datetime(X[col], format='%Y-%m-%d', errors='coerce')\n\n            # Extracting year,day,month,etc.\n#            X[f'{col}_Year'] = X[col].dt.year\n#            X[f'{col}_Month'] = X[col].dt.month\n#            X[f'{col}_Day'] = X[col].dt.day\n#            X[f'{col}_Weekday'] = X[col].dt.weekday  # 0 = Monday\n\n            # Time since earliest date in dataset\n#            X[f'{col}_ElapsedDays'] = (X[col] - X[col].min()).dt.days\n\n#            X.drop(columns=[col], inplace=True)\n        \n#        return X\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:08.342817Z","iopub.execute_input":"2025-03-21T02:51:08.343213Z","iopub.status.idle":"2025-03-21T02:51:08.347590Z","shell.execute_reply.started":"2025-03-21T02:51:08.343176Z","shell.execute_reply":"2025-03-21T02:51:08.346666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#date_cols = ['DateAS', 'DateOS']  # Date columns\n#date_transformer = DateTransformer(date_columns=date_cols)\n\n# Applying transformation\n#train_df = date_transformer.fit_transform(train_df)\n#test_df = date_transformer.transform(test_df)\n\n#print(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:08.348674Z","iopub.execute_input":"2025-03-21T02:51:08.349053Z","iopub.status.idle":"2025-03-21T02:51:08.381529Z","shell.execute_reply.started":"2025-03-21T02:51:08.349019Z","shell.execute_reply":"2025-03-21T02:51:08.380594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Seperating Target Column**","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(columns=['target'])\ny = train_df['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:08.382480Z","iopub.execute_input":"2025-03-21T02:51:08.382753Z","iopub.status.idle":"2025-03-21T02:51:08.434950Z","shell.execute_reply.started":"2025-03-21T02:51:08.382730Z","shell.execute_reply":"2025-03-21T02:51:08.434036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Train-Validation Split**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n#'stratify=y' ensures class balance in train & validation splits.\n\nprint(f\"Training set size: {X_train.shape[0]} samples\")\nprint(f\"Validation set size: {X_val.shape[0]} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:08.435882Z","iopub.execute_input":"2025-03-21T02:51:08.436263Z","iopub.status.idle":"2025-03-21T02:51:08.583875Z","shell.execute_reply.started":"2025-03-21T02:51:08.436228Z","shell.execute_reply":"2025-03-21T02:51:08.583047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Identify Numeric and Categorical Columns**","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Numerical and categorical columns\nnum_cols = X_train.select_dtypes(include=np.number).columns.tolist()\ncat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:08.584756Z","iopub.execute_input":"2025-03-21T02:51:08.585080Z","iopub.status.idle":"2025-03-21T02:51:08.853873Z","shell.execute_reply.started":"2025-03-21T02:51:08.585048Z","shell.execute_reply":"2025-03-21T02:51:08.853064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline for numerical features\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),  # Handling the missing values\n    ('scaler', StandardScaler())  # Normalizing data\n])\n\n# Pipeline for categorical features\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handling the missing values\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Encoding categorical features\n])\n\n# Combining both pipelines\npreprocessor = ColumnTransformer([\n    ('num', num_pipeline, num_cols),\n    ('cat', cat_pipeline, cat_cols)\n])\n\n\nX_train_processed = preprocessor.fit_transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\n\nprint(\"Missing values in X_train_processed:\", np.sum(pd.isna(X_train_processed)))\nprint(\"Missing values in X_val_processed:\", np.sum(pd.isna(X_val_processed)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:08.854688Z","iopub.execute_input":"2025-03-21T02:51:08.854923Z","iopub.status.idle":"2025-03-21T02:51:11.427825Z","shell.execute_reply.started":"2025-03-21T02:51:08.854902Z","shell.execute_reply":"2025-03-21T02:51:11.426731Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **4. Model Building**","metadata":{}},{"cell_type":"markdown","source":"**4a. Logestic Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(max_iter=2000, random_state=42)\nlog_reg.fit(X_train_processed, y_train)\ny_val_pred = log_reg.predict(X_val_processed)\n\n#model performance\nacc = accuracy_score(y_val, y_val_pred)\nf1 = f1_score(y_val, y_val_pred)\nreport = classification_report(y_val, y_val_pred)\n\nprint(f\"Logistic Regression - Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\nprint(\"\\nClassification Report:\\n\", report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:11.428835Z","iopub.execute_input":"2025-03-21T02:51:11.429118Z","iopub.status.idle":"2025-03-21T02:51:48.026859Z","shell.execute_reply.started":"2025-03-21T02:51:11.429094Z","shell.execute_reply":"2025-03-21T02:51:48.025972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submit_for_score(log_reg))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:48.027747Z","iopub.execute_input":"2025-03-21T02:51:48.028041Z","iopub.status.idle":"2025-03-21T02:51:48.031796Z","shell.execute_reply.started":"2025-03-21T02:51:48.028017Z","shell.execute_reply":"2025-03-21T02:51:48.030750Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4b. Decision Tree Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train_processed, y_train)\ny_val_pred = dt_model.predict(X_val_processed)\n\ndt_accuracy = accuracy_score(y_val, y_val_pred)\ndt_report = classification_report(y_val, y_val_pred)\n\nprint(f\"Decision Tree - Accuracy: {dt_accuracy:.4f}\")\nprint(\"\\nClassification Report:\\n\", dt_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:48.032768Z","iopub.execute_input":"2025-03-21T02:51:48.033094Z","iopub.status.idle":"2025-03-21T02:53:14.500680Z","shell.execute_reply.started":"2025-03-21T02:51:48.033070Z","shell.execute_reply":"2025-03-21T02:53:14.499569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submit_for_score(dt_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:53:14.502079Z","iopub.execute_input":"2025-03-21T02:53:14.502483Z","iopub.status.idle":"2025-03-21T02:53:14.505982Z","shell.execute_reply.started":"2025-03-21T02:53:14.502447Z","shell.execute_reply":"2025-03-21T02:53:14.505096Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4c. Random Forest Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\nrf_model.fit(X_train_processed, y_train)\ny_val_pred = rf_model.predict(X_val_processed)\n\nrf_accuracy = accuracy_score(y_val, y_val_pred)\nrf_report = classification_report(y_val, y_val_pred)\n\nprint(f\"Random Forest - Accuracy: {rf_accuracy:.4f}\")\nprint(\"\\nClassification Report:\\n\", rf_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:53:14.506782Z","iopub.execute_input":"2025-03-21T02:53:14.507088Z","iopub.status.idle":"2025-03-21T02:58:46.642973Z","shell.execute_reply.started":"2025-03-21T02:53:14.507064Z","shell.execute_reply":"2025-03-21T02:58:46.642111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submit_for_score(rf_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:58:46.643850Z","iopub.execute_input":"2025-03-21T02:58:46.644108Z","iopub.status.idle":"2025-03-21T02:58:46.647743Z","shell.execute_reply.started":"2025-03-21T02:58:46.644086Z","shell.execute_reply":"2025-03-21T02:58:46.646822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4d. XGBoost**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\nxgb_model.fit(X_train_processed, y_train)\ny_val_pred = xgb_model.predict(X_val_processed)\n\nxgb_accuracy = accuracy_score(y_val, y_val_pred)\nxgb_report = classification_report(y_val, y_val_pred)\n\nprint(f\"XGBoost - Accuracy: {xgb_accuracy:.4f}\")\nprint(\"\\nClassification Report:\\n\", xgb_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:58:46.648673Z","iopub.execute_input":"2025-03-21T02:58:46.648947Z","iopub.status.idle":"2025-03-21T02:59:00.737841Z","shell.execute_reply.started":"2025-03-21T02:58:46.648926Z","shell.execute_reply":"2025-03-21T02:59:00.736993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submit_for_score(xgb_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:59:00.738581Z","iopub.execute_input":"2025-03-21T02:59:00.738817Z","iopub.status.idle":"2025-03-21T02:59:00.742515Z","shell.execute_reply.started":"2025-03-21T02:59:00.738797Z","shell.execute_reply":"2025-03-21T02:59:00.741561Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4e. LightGBM**","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgbm_model = LGBMClassifier(n_estimators=100, random_state=42)\nlgbm_model.fit(X_train_processed, y_train)\ny_val_pred = lgbm_model.predict(X_val_processed)\n\naccuracy = accuracy_score(y_val, y_val_pred)\nprint(\"LightGBM - Accuracy:\", round(accuracy, 4))\nprint(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:59:00.746041Z","iopub.execute_input":"2025-03-21T02:59:00.746370Z","iopub.status.idle":"2025-03-21T02:59:07.207547Z","shell.execute_reply.started":"2025-03-21T02:59:00.746345Z","shell.execute_reply":"2025-03-21T02:59:07.206518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submit_for_score(lgbm_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:59:07.208890Z","iopub.execute_input":"2025-03-21T02:59:07.209721Z","iopub.status.idle":"2025-03-21T02:59:07.213210Z","shell.execute_reply.started":"2025-03-21T02:59:07.209673Z","shell.execute_reply":"2025-03-21T02:59:07.212443Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Performance Comparison\n\n| Model               | Accuracy | F1-Score (Class 1) | F1-Score (Class 0) | Precision (Class 1) | Precision (Class 0) | Recall (Class 1) | Recall (Class 0) |\n|---------------------|----------|--------------------|---------------------|----------------------|---------------------|------------------|------------------|\n| **Logistic Regression** | 0.6122 | 0.6332 | 0.59 | 0.61 | 0.62 | 0.66 | 0.56 |\n| **Decision Tree**      | 0.5568  | 0.56   | 0.55 | 0.56  | 0.55 | 0.57  | 0.55 |\n| **Random Forest**       | 0.6064  | 0.62   | 0.59 | 0.60  | 0.61 | 0.64  | 0.57 |\n| **XGBoost**            | 0.6254 | 0.64 | 0.61 | 0.62  | 0.63 | 0.67 | 0.58 |\n| **LightGBM**           | 0.6287 | 0.65 | 0.61 | 0.62  | 0.64 | 0.67 | 0.59|\n\n**Key Observations**\n* Decision Tree performed the worst with the lowest accuracy (0.5568)\n* Logistic Regression performed slightly better than Random Forest but still not the best choice.\n* XGBoost and LightGBM had the best performance in terms of accuracy (0.63) and F1-score (0.64-0.65), showing better generalization.\n* LightGBM slightly outperformed XGBoost in accuracy and recall, making it a strong candidate.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**XGBoost and LightGBM** gave the best result\n* Higher Performance: Both models achieved the highest accuracy and F1-scores, meaning they generalize better on unseen data.\n* Better Recall: XGBoost and LightGBM had the highest recall for Class 1 (~0.67), making them ideal when missing positive cases is costly.\n* Scalability: LightGBM handles large datasets efficiently due to its histogram-based learning.","metadata":{}},{"cell_type":"markdown","source":"# **5. HyperParameter Tuning**","metadata":{}},{"cell_type":"markdown","source":"**5a. XGBoost HPT**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\n\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n\n# parameter grid\nparam_dist = {\n    'n_estimators': [100, 300, 500],\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.7, 0.8, 0.9],\n    'colsample_bytree': [0.7, 0.8, 0.9]\n}\n\n# Randomized search\nrandom_search = RandomizedSearchCV(\n    xgb_model, param_distributions=param_dist, n_iter=10, \n    scoring='f1', cv=3, verbose=2, n_jobs=-1\n)\n\nrandom_search.fit(X_train_processed, y_train)\n\nbest_params = random_search.best_params_\nprint(\"Best Parameters:\", best_params)\n\n# Training final XGBoost model with best parameters\nbest_xgb = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\nbest_xgb.fit(X_train_processed, y_train)\n\ny_val_pred = best_xgb.predict(X_val_processed)\n\nprint(\"Optimized XGBoost Model Performance:\")\nprint(classification_report(y_val, y_val_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:59:07.214247Z","iopub.execute_input":"2025-03-21T02:59:07.214562Z","iopub.status.idle":"2025-03-21T03:12:35.333609Z","shell.execute_reply.started":"2025-03-21T02:59:07.214538Z","shell.execute_reply":"2025-03-21T03:12:35.332476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submit_for_score(best_xgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T03:12:35.334862Z","iopub.execute_input":"2025-03-21T03:12:35.335232Z","iopub.status.idle":"2025-03-21T03:12:35.830002Z","shell.execute_reply.started":"2025-03-21T03:12:35.335196Z","shell.execute_reply":"2025-03-21T03:12:35.828963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**5b. LightGBM HPT**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nimport lightgbm as lgb\n\n# parameter grid\nparam_dist = {\n    'num_leaves': [20, 31, 40, 50],\n    'max_depth': [5, 10, 15, -1],  # -1 means no limit\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'n_estimators': [200, 500, 1000],\n    'subsample': [0.7, 0.8, 0.9, 1.0],\n    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n}\n\nlgb_model = lgb.LGBMClassifier()\n\n#Randomized Search\nrandom_search = RandomizedSearchCV(\n    estimator=lgb_model, \n    param_distributions=param_dist, \n    n_iter=10,  # Number of different parameter combinations to try\n    scoring='accuracy',\n    cv=3,  # 3-fold cross-validation\n    verbose=2, \n    random_state=42, \n    n_jobs=-1\n)\n\nrandom_search.fit(X_train_processed, y_train)\n\nprint(\"Best Parameters:\", random_search.best_params_)\n\n# Evaluating the best model\nbest_lgbm_model = random_search.best_estimator_\ny_pred = best_lgbm_model.predict(X_val_processed)\n\nprint(\"Optimized LightGBM Model Performance:\")\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T03:12:35.831052Z","iopub.execute_input":"2025-03-21T03:12:35.831441Z","iopub.status.idle":"2025-03-21T03:19:19.243338Z","shell.execute_reply.started":"2025-03-21T03:12:35.831406Z","shell.execute_reply":"2025-03-21T03:19:19.242253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submit_for_score(best_lgbm_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T03:19:19.244404Z","iopub.execute_input":"2025-03-21T03:19:19.244775Z","iopub.status.idle":"2025-03-21T03:19:19.249137Z","shell.execute_reply.started":"2025-03-21T03:19:19.244740Z","shell.execute_reply":"2025-03-21T03:19:19.248105Z"}},"outputs":[],"execution_count":null}]}